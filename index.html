<!DOCTYPE html>
<html>
<head>
  <!-- Load Latex -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <meta charset="utf-8">
  <meta name="description"
        content="LIM: Large Interpolator Model for Dynamic Reconstruction">
  <meta name="keywords" content="LIM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LIM: Large Interpolator Model for Dynamic Reconstruction</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <!-- Navigation Bar -->
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">

        <!-- <a class="navbar-item" href="TODO!!!">
        <span class="icon">
            <i class="fas fa-home"></i>
        </span>
        </a> -->

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://remysabathier.github.io/animalavatar.github.io/">
              AnimalAvatar
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">

          <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">LIM: Large Interpolator Model for Dynamic Reconstruction</h1>
              <h2 class="title is-4 publication-title">CVPR 2025</span></h2>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="https://profiles.ucl.ac.uk/96179-remy-sabathier">Remy Sabathier</a><sup>1,2</sup>,</span>
                  <span class="author-block">
                    <a href="http://www0.cs.ucl.ac.uk/staff/n.mitra/">Niloy J. Mitra</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://d-novotny.github.io/">David Novotny</a><sup>2</sup>,</span>
              </div>
              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>University College London,</span>
                <span class="author-block"><sup>2</sup>Meta</span>
              </div>


              <div class="column has-text-centered">
              <div class="publication-links">

                <!-- Arxiv Link. -->
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv (Soon)</span>
                  </a>
                </span>

                <!-- Code Link. -->
                <span class="link-block">
                  <a href=""
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Soon)</span>
                    </a>
                </span>


              </div>
            </div>
          </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Abstract. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
        <p>
        Reconstructing dynamic assets from video data is central to many in computer vision and graphics tasks.
        Existing 4D reconstruction approaches are limited by category-specific models or slow optimization-based methods.
        Inspired by the recent Large Reconstruction Model (LRM), we present the <b>Large Interpolation Model</b> (<span class="lim">LIM</span>), a transformer-based feed-forward solution, guided by a novel causal consistency loss, for interpolating implicit 3D representations across time.
        Given implicit 3D representations at times \( t_{0} \) and \( t_{1} \), LIM produces a deformed shape at any continuous time \( t \in [t_{0},t_{1}] \)  delivering high-quality interpolations in seconds (per frame).
        Furthermore, LIM allows explicit mesh tracking across time, producing a consistently uv-textured mesh sequence ready for integration into existing production pipelines.
        We also use LIM, in conjunction with a diffusion-based multiview generator, to produce dynamic 4D reconstructions from monocular videos.
        We evaluate LIM on various dynamic datasets, benchmarking against image-space interpolation methods (e.g., FiLM [3]) and direct triplane linear interpolation, and demonstrate clear advantages.
        In summary, LIM is the first feed-forward model capable of high-speed tracked 4D asset reconstruction across diverse categories.
      </p>

      <div style="text-align: center; margin-top: 20px;">
        <div class="button-container">
            <button class="choice-button" id="buttonRGB" onclick="changeContent('RGB')">\(\text{LIM}\)</button>
            <button class="choice-button" id="buttonXYZ" onclick="changeContent('XYZ')">\(\overline{\text{LIM}}\)</button>
        </div>
        <img id="image" src="" height="10%">
        <figcaption id="caption">
          Select a version of LIM.
        </figcaption>
    </div>
    <style>
        .button-container {
            display: flex;
            justify-content: center;
            margin-top: 20px;
        }
        .choice-button {
            font-size: 18px;
            padding: 5px 10px;
            margin: 0 10px;
            cursor: pointer;
            border: 2px solid transparent;
        }
        .active {
            border-color: blue; /* Change this color to your preferred active color */
            background-color: lightblue; /* Optional: add a background color for the active button */
        }
    </style>
    <script>
        function changeContent(choice) {
            const image = document.getElementById('image');
            const caption = document.getElementById('caption');
            const buttonRGB = document.getElementById('buttonRGB');
            const buttonXYZ = document.getElementById('buttonXYZ');
            if (choice === 'RGB') {
                image.src = 'static/images/lim_rgb_architecture.png'; // Update with the correct path for the RGB image
                caption.innerHTML = `
                  Figure1: <b><span class="lim">LIM</span> Architecture</b>.
                  (Left) Given multi-view images on 2 timesteps \\( k \\) and \\( k+1 \\), <span class="limblack">LIM</span> interpolates any intermediate 3D representation at \\( k+\\alpha, \\alpha \\in [0,1] \\).
                  It achieves this notably via cross-attention with the latest intermediate features of <span class="limblack">LRM</span> on keyframe \\( k \\).
                  In practice, our <span class="limblack">LIM</span> architecture has 6 blocks and <span class="limblack">LRM</span> 12 blocks.
                  (Right) Block structure of <span class="limblack">LRM</span> and <span class="limblack">LIM</span>.
                  We include layer normalization before each module in blocks.
                `;
                buttonRGB.classList.add('active');
                buttonXYZ.classList.remove('active');
            } else if (choice === 'XYZ') {
                image.src = 'static/images/lim_xyz_architecture.png'; // Update with the correct path for the XYZ image
                caption.innerHTML = `
                  Figure1 bis: <b><span class="limxyz">LIM</span> Architecture</b>.
                  (Left) Given multi-view RGB images on 2 timesteps \\( k \\) and \\( k+1 \\) and XYZ canonical-coordinate renders on timestep \\( k \\), <span class="limxyzblack">LIM</span> interpolates any intermediate 3D representation of the XYZ canonical-coordinates at \\( k+\\alpha, \\alpha \\in [0,1] \\).
                  It achieves this notably via cross-attention with the latest intermediate features of <span class="limxyzblack">LRM</span> on keyframe \\( k \\).
                  This gives direct correspondences in 3D space between the source shape at \\( k \\)  and the interpolated shape at \\( k+\\alpha \\).
                  In practice, our <span class="limxyzblack">LIM</span> architecture has 6 blocks and <span class="limxyzblack">LIM</span> 12 blocks.
                  (Right) Block structure of <span class="limxyzblack">LRM</span> and <span class="limxyzblack">LIM</span>.
                  We include layer normalization before each module in blocks.
                `;
                buttonXYZ.classList.add('active');
                buttonRGB.classList.remove('active');
            }
          // Render the LaTeX
          MathJax.typeset();
        }
        // Initialize the default active button
        document.getElementById('buttonRGB').classList.add('active');
    </script>
  </div>
</section>
<!--/ Abstract. -->


<!-- Interpolation -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="container is-centered has-text-centered">
      <h2 class="title is-3">Frame Interpolation</h2>
      <div class="content is-centered has-text-centered has-text-justified">
        <p>
          Our first model, <span class="lim">LIM</span> directly interpolates color & opacity-field in 3D space in the multi-view setting.
          We observe that:
          <b>(i)</b> Linear interpolation in triplane space fails on dynamic parts
          <b>(ii)</b> Image-based interpolation (FILM [3]) in the multi-view setting leads to defective reconstructions (with ghosting around dynamic parts)
          <b>(iii)</b> <span class="lim">LIM</span> yields the most plausible results, without artifacts.
        </p>
      </div>
      <!-- Add the video here -->
      <div class="video-container">
        <video autoplay loop muted class="is-centered">
          <source src="static/images/qualitative_interpolation.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <figcaption>
        Figure2: <b>Frame Interpolation</b>.
        We add 2 interpolated frames between each frame rendered from multi-view LRM.
        Oracle is the upper-bound limit, where we perform LRM reconstruction with multi-views images on all frames
        (including the ones interpolated by the 3 methods).
        For each method, we render the video with the LRM renders and the interpolated frames in-between.
        We highlight a single interpolation step at the end.
      </figcaption>
      <!-- End video -->
    </div>
  </div>
</section>
  <!-- Interpolation -->


  <!-- XYZ Interpolation -->
<section class="section">
    <div class="container is-max-desktop">
      <div class="container is-centered has-text-centered">
        <h2 class="title is-3">4D Reconstruction</h2>
        <div class="content is-centered has-text-centered has-text-justified">
          <p>
            An extension of our model, <span class="limxyz">LIM</span>, can trace the deformable shape through time.
            Given a multi-view sequence with RGB inputs, we start by extracting the triplane on the first frame with LRM.
            We render the triplane to obtain a depth map that we unproject to get multi-view renders of
            <span class="blue">X</span><span class="magenta">Y</span><span class="yellow">Z</span>
            coordinates on the first (=canonical) frame.
            Finally, from the XYZ renders on the first frame, and RGB inputs on all the frames,
            <span class="limxyzblack">LIM</span> propagates the XYZ canonical coordinates on the first timestep to the other steps.
          <p>
        </div>

      <img id="image" src="static/images/4dtrack_pipeline.png" width="80%">
      <figcaption>
        Figure3: <b>XYZ coordinates tracking</b>.
        <span class="limxyz">LIM</span> interpolates the XYZ coordinates on the first (=canonical) frame to the next ones.
      </figcaption>

    </div>
    </div>
  </section>
  <!-- XYZ Interpolation -->


  <!-- Mesh deformation -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="container is-centered has-text-centered">
        <div class="content is-centered has-text-centered has-text-justified">
          <p>
            We use these surface annotations to output a time-deforming mesh with fixed topology and texture.
          <p>
        </div>
      <!-- Add the video here -->
      <div class="video-container">
        <video autoplay loop muted class="is-centered">
          <source src="static/images/mesh_renders.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <figcaption>
        Figure4: <b>Mesh deformation</b>.  We leverage LRM, <span class="lim">LIM</span> and <span class="limxyz">LIM</span> to reconstruct a time-deforming mesh with fixed topology, in the multi-view setting.
      </figcaption>
      <!-- End video -->
      </div>
      </div>
    </div>
  </section>
  <!-- Mesh deformation -->


<!-- 4D Reconstruction -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="container is-centered has-text-centered">
      <h2 class="title is-3">Application: Monocular Reconstruction</h2>
      <div class="content is-centered has-text-centered has-text-justified">
        <p>
          We show extension of our framework to the monocular reconstruction setting.
          We observe that results from <b>TripoSR</b> [2] (image-to-3D reconstructor) jitters since the frames are reconstructed independently.
          <b>Consistent4D</b> [1] renders are consistent in time, but the method is slow.
          Our method combined with a monocular-to-multiview video diffusion model is consistent in time and significantly faster.
        </p>
      </div>
      <!-- Add the video here -->
      <div class="video-container">
        <video autoplay loop muted class="is-centered">
          <source src="static/images/qualitative_monocular.mp4" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
      <figcaption>Figure5: <b>Monocular Reconstruction</b> </figcaption>
      <!-- End video -->
    </div>
  </div>
</section>
<!-- 4D Reconstruction -->


  <!-- Related work -->
  <section class="section" id="Related work">
    <div class="container is-max-desktop content">
      <h2 class="title">Related Work</h2>
      <ul>
        <li>
          <b>[1]</b> Yanqin Jiang, Li Zhang, Jin Gao, Weimin Hu, Yao Yao (2024).
          <b>Consistent4D</b>: Consistent 360deg Dynamic Object Generation from Monocular Video.
          <a href="https://arxiv.org/abs/2311.02848"> (link)</a>
        </li>
        <li>
          <b>[2]</b> Dmitry Tochilkin, David Pankratz, Zexiang Liu, Zixuan Huang, Adam Letts, Yangguang Li, Ding Liang, Christian Laforte, Varun Jampani, Yan-Pei Cao (2024).
          <b>TripoSR</b>: Fast 3D Object Reconstruction from a Single Image.
          <a href="https://arxiv.org/abs/2403.02151"> (link)</a>
        </li>
        <li>
          <b>[3]</b> Fitsum Reda, Janne Kontkanen, Eric Tabellion, Deqing Sun, Caroline Pantofaru, Brian Curless (2022).
          <b>FILM</b>: Frame Interpolation for Large Motion
          <a href="https://arxiv.org/abs/2202.04901"> (link)</a>
        </li>
      </ul>
    </div>
  </section>
  <!-- Related work -->

  <footer>
    Template inspired by <a href="https://github.com/nerfies/nerfies.github.io">Nerfies.</a>
  </footer>


</body>
</html>
